{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load preprocessed data\n",
    "\n",
    "X = pd.read_feather('./X.ftr')\n",
    "y = pd.read_feather('./tags.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {} #dictionary to store the final trained models\n",
    "num_tags = 100 #number of tags to be used\n",
    "num_questions_per_tag = 1000 #number of questions(+ve and -ve each) to be used as data for classifier\n",
    "num_words_per_tag = 100 #no.of features per tag\n",
    "\n",
    "#get the 'num_tags' most frequently used tags\n",
    "\n",
    "tags_count = y.groupby('Tag')['Id'].nunique().sort_values(ascending=False).reset_index(name='count').head(num_tags)\n",
    "tags_to_use = tags_count['Tag']\n",
    "\n",
    "#extract features and build model for each tag\n",
    "\n",
    "for tag in tags_to_use:\n",
    "    question_ids = set() #set of question ids for the current tag\n",
    "    pos_tag_question_ids, neg_tag_question_ids = [], [] #lists of question ids of +ve and -ve examples respectively\n",
    "    pos_count, neg_count, i = 0, 0, 0\n",
    "    while (pos_count<num_questions_per_tag or neg_count<num_questions_per_tag) and i<y.shape[0]:\n",
    "        if y.loc[y.index[i], 'Tag']==tag and pos_count<num_questions_per_tag:\n",
    "            if y.loc[y.index[i], 'Id'] in neg_tag_question_ids:\n",
    "                neg_tag_question_ids.remove(y.loc[y.index[i], 'Id'])\n",
    "            pos_tag_question_ids.append(y.loc[y.index[i], 'Id'])\n",
    "            pos_count+=1\n",
    "        elif y.loc[y.index[i], 'Tag']!=tag and neg_count<num_questions_per_tag and y.loc[y.index[i], 'Id'] not in pos_tag_question_ids and y.loc[y.index[i], 'Id'] not in neg_tag_question_ids:\n",
    "            neg_tag_question_ids.append(y.loc[y.index[i], 'Id'])\n",
    "            neg_count+=1\n",
    "        i+=1\n",
    "    question_ids.update(pos_tag_question_ids)\n",
    "    question_ids.update(neg_tag_question_ids)\n",
    "    X_with_valid_tags = X[X['Id'].isin(question_ids)] #dataframe containing questions to be used for current tag\n",
    "    \n",
    "    word_features = set() #set of words to be used as features\n",
    "    tag_word_features = {}\n",
    "    for i in range(X_with_valid_tags.shape[0]):\n",
    "        if X_with_valid_tags.loc[X_with_valid_tags.index[i], 'Id'] in pos_tag_question_ids:\n",
    "            for word in nltk.tokenize.word_tokenize(X_with_valid_tags.iloc[i, 0]):\n",
    "                if word not in tag_word_features:\n",
    "                    tag_word_features[word] = 1\n",
    "                else:\n",
    "                    tag_word_features[word] += 1\n",
    "            for word in nltk.tokenize.word_tokenize(X_with_valid_tags.iloc[i, 1]):\n",
    "                if word not in tag_word_features:\n",
    "                    tag_word_features[word] = 1\n",
    "                else:\n",
    "                    tag_word_features[word] += 1\n",
    "    tag_word_features = sorted(tag_word_features.items(), key=lambda item: item[1], reverse=True)\n",
    "    tag_word_features = [item[0] for item in tag_word_features[:num_words_per_tag]]\n",
    "    word_features.update(tag_word_features)\n",
    "    \n",
    "    #populate the feature columns of the input dataframe\n",
    "    for word in word_features:\n",
    "        X_with_valid_tags[word] = 0\n",
    "    for i in range(X_with_valid_tags.shape[0]):\n",
    "        for word in nltk.tokenize.word_tokenize(X_with_valid_tags.iloc[i, 0]):\n",
    "            if word in word_features:\n",
    "                X_with_valid_tags.loc[X_with_valid_tags.index[i], word] = 1\n",
    "        for word in nltk.tokenize.word_tokenize(X_with_valid_tags.iloc[i, 1]):\n",
    "            if word in word_features:\n",
    "                X_with_valid_tags.loc[X_with_valid_tags.index[i], word] = 1\n",
    "    \n",
    "    #populate the output labels\n",
    "    y_with_valid_tags = pd.DataFrame()\n",
    "    y_with_valid_tags[tag] = 0\n",
    "    for i in range(X_with_valid_tags.shape[0]):\n",
    "        if X_with_valid_tags.loc[X_with_valid_tags.index[i], 'Id'] in pos_tag_question_ids:\n",
    "            y_with_valid_tags.loc[X_with_valid_tags.index[i], tag] = 1\n",
    "        else:\n",
    "            y_with_valid_tags.loc[X_with_valid_tags.index[i], tag] = 0\n",
    "    \n",
    "    #build and train the model and add it to the models and features used by them to the 'models' dictionary\n",
    "    X_with_valid_tags.drop(['Id', 'Title', 'Body'], axis=1, inplace=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_with_valid_tags, y_with_valid_tags, test_size=0.2, random_state=0)\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    models[tag] = {'features':word_features, 'model': clf}\n",
    "    print(\"Tag: \" + tag, \"Train Accuracy: \" + str(clf.score(X_train, y_train)), \"Test Accuracy: \" + str(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the models as pickle\n",
    "\n",
    "output = open('./models.pkl', 'wb')\n",
    "pickle.dump(models, output)\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
